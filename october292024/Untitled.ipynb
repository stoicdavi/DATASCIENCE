{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cd8ef6-f1a0-4aa8-a023-270f6f2017c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "zu/1195 Wainaina George\n",
    "3:04 PM\n",
    "import pandas as pd\n",
    "wainaina = pd.read_csv('/content/boston-housing-dataset.csv')\n",
    "print(\"Shape of the dataset:\", wainaina.shape)\n",
    "wainaina.head(20)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "wainaina = pd.read_csv('/content/boston-housing-dataset.csv')\n",
    "data=wainaina.loc[:,['LSTAT','MEDV']]\n",
    "data.head(20)\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "wainaina = pd.read_csv('/content/boston-housing-dataset.csv')\n",
    "wainaina.plot(x='LSTAT',y='MEDV',style='o')\n",
    "plt.xlabel('LSTAT')\n",
    "plt.ylabel('MEDV')\n",
    "plt.show()\n",
    "\n",
    "import pandas as pd\n",
    "wainaina = pd.read_csv('/content/boston-housing-dataset.csv')\n",
    "x=pd.DataFrame(data['LSTAT'])\n",
    "y=pd.DataFrame(data['MEDV'])\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "wainaina = pd.read_csv('/content/boston-housing-dataset.csv')\n",
    "x=pd.DataFrame(data['LSTAT'])\n",
    "y=pd.DataFrame(data['MEDV'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_n.shape)\n",
    "print(y_testrait.shape)\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor=LinearRegression()\n",
    "regressor.fit(X_train,y_train)\n",
    "print(regressor.intercept_)\n",
    "print(regressor.coef_)\n",
    "y_pred = regressor.predict(X_test)\n",
    "y_pred\n",
    "#y_test\n",
    "#print(y_test)\n",
    "y_test.head(20)\n",
    "\n",
    "\n",
    "zu/1195 Wainaina George\n",
    "3:17 PM\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "# Assuming y_test and y_pred are NumPy arrays or Pandas Series\n",
    "mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse) # RMSE is the square root of MSE\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# Load the data\n",
    "wainaina = pd.read_csv('/content/boston-housing-dataset.csv')\n",
    "# Extract the independent variable (X) and dependent variable (y)\n",
    "X = wainaina[['LSTAT']]\n",
    "y = wainaina['MEDV']\n",
    "# Create and fit a linear regression model\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X, y)\n",
    "# Plot the data points\n",
    "wainaina.plot(x='LSTAT', y='MEDV', style='o', label='Data Points')\n",
    "# Overlay the regression line\n",
    "plt.plot(X, regressor.predict(X), color='red', linewidth=2, label='Regression Line')\n",
    "plt.xlabel('LSTAT')\n",
    "plt.ylabel('MEDV')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "import joblib\n",
    "import pickle # Import the pickle module\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# Train your linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(x, y) # Replace X and y with your training data\n",
    "# Save the trained model to a file using joblib\n",
    "joblib.dump(model, 'linear_regression_model.pkl')\n",
    "# Alternatively, you can save the model using pickle\n",
    "with open('linear_regression_model.pkl', 'wb') as file:\n",
    "pickle.dump(model, file)\n",
    "\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Sample X values for prediction\n",
    "new_X = np.array([9.8, 7, 8, 9, 10]).reshape(-1, 1) # Reshape to a 2D array\n",
    "# Load the trained model\n",
    "model = joblib.load('linear_regression_model.pkl') # Load your trained model here\n",
    "# Make predictions on the new X values\n",
    "predictions = model.predict(new_X)\n",
    "# Create a DataFrame with one-dimensional arrays\n",
    "new_data = pd.DataFrame({'X': new_X.flatten(), 'Predicted_Y': predictions.flatten()})\n",
    "# Display the new_data DataFrame with the X values and the predicted Y values\n",
    "print(new_data)\n",
    "\n",
    "\n",
    "from google.colab import files\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.patches as mpatches\n",
    "#Upload the image\n",
    "uploaded = files.upload()\n",
    "image = cv2.imdecode(np.frombuffer(uploaded[next(iter(uploaded))], np.uint8), -1)\n",
    "# Load and preprocess the image\n",
    "#image = cv2.imread('WAINAINA.jpg')\n",
    "#image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "height, width, _ = image.shape\n",
    "reshaped_image = image.reshape(-1, 3)\n",
    "# Perform K-Means clustering\n",
    "k = 3 # Number of clusters\n",
    "kmeans = KMeans(n_clusters=k, random_state=0).fit(reshaped_image)\n",
    "labels = kmeans.labels_\n",
    "centers = kmeans.cluster_centers_\n",
    "# Create a color-coded segmentation map\n",
    "segmented_image = centers[labels].reshape(height, width, 3).astype('uint8')\n",
    "# Create a title for the output\n",
    "title = f\"Image Segmentation with {k} Clusters\"\n",
    "# Define segment labels based on colors\n",
    "segment_labels = [f\"Segment {i+1}\" for i in range(k)]\n",
    "# Visualize the segmented image with title and a legend for colors\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Display the segmented image\n",
    "plt.imshow(segmented_image)\n",
    "plt.axis('off')\n",
    "# Add a title using plt.title\n",
    "plt.title(title, fontsize=16, fontweight='bold')\n",
    "# Create a legend for colors\n",
    "legend_patches = [mpatches.Patch(color=centers[i] / 255, label=segment_labels[i]) for i in range(k)]\n",
    "plt.legend(handles=legend_patches, loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "# Load the image\n",
    "image = cv2.imread('/content/ZETECH.jpg')\n",
    "if image is None:\n",
    "print(\"Image not found\")\n",
    "else:\n",
    "# Convert the image to grayscale for simplicity\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "# Reshape the image into a flat 1D array for clustering\n",
    "reshaped_image = gray_image.reshape(-1, 1)\n",
    "# Perform K-Means clustering to identify the two dominant colors\n",
    "kmeans = KMeans(n_clusters=2, random_state=0)\n",
    "kmeans.fit(reshaped_image)\n",
    "# Find the two cluster centers\n",
    "cluster_centers = kmeans.cluster_centers_.astype(int)\n",
    "# Sort cluster centers by color intensity\n",
    "sorted_cluster_centers = sorted(cluster_centers, key=lambda x: sum(x))\n",
    "# Define a threshold value to distinguish between the two clusters\n",
    "threshold = (sorted_cluster_centers[0][0] + sorted_cluster_centers[1][0]) // 2\n",
    "# Extract the hidden message from pixel values\n",
    "decoded_bits = [1 if pixel > threshold else 0 for pixel in reshaped_image]\n",
    "# Reconstruct the message by grouping bits and converting to characters\n",
    "message_bits = [decoded_bits[i:i+8] for i in range(0, len(decoded_bits), 8)]\n",
    "decoded_message = ''.join([chr(int(''.join(map(str, bits)), 2)) for bits in message_bits])\n",
    "print(\"Decoded Hidden Message:\")\n",
    "print(decoded_message)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "# Generate synthetic patient data\n",
    "np.random.seed(0)\n",
    "n_samples = 200\n",
    "n_features = 2\n",
    "# Create two distinct patient clusters\n",
    "cluster1 = np.random.randn(n_samples // 2, n_features) + np.array([2, 2])\n",
    "cluster2 = np.random.randn(n_samples // 2, n_features) + np.array([-2, -2])\n",
    "patient_data = np.vstack([cluster1, cluster2])\n",
    "# Create a DataFrame for visualization\n",
    "data_df = pd.DataFrame(patient_data, columns=['Feature1', 'Feature2'])\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "patient_data_std = scaler.fit_transform(patient_data)\n",
    "# Apply K-Means clustering\n",
    "n_clusters = 3\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "data_df['Cluster'] = kmeans.fit_predict(patient_data_std)\n",
    "# Visualize the patient clusters\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(data_df['Feature1'], data_df['Feature2'], c=data_df['Cluster'], cmap='viridis')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('Patient Clusters in Clinical Care')\n",
    "plt.show()\n",
    "# Analyze cluster characteristics (e.g., for disease management)\n",
    "cluster_centers = scaler.inverse_transform(kmeans.cluster_centers_)\n",
    "print('Cluster Centers:')\n",
    "print(pd.DataFrame(cluster_centers, columns=['Feature1', 'Feature2']))\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "# Function to preprocess the data\n",
    "def preprocess_data(data):\n",
    "label_encoder = LabelEncoder()\n",
    "data['smoker'] = label_encoder.fit_transform(data['smoker'])\n",
    "data['sex'] = label_encoder.fit_transform(data['sex'])\n",
    "X = data[['age', 'charges']]\n",
    "scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(X)\n",
    "return X_std\n",
    "\n",
    "# Function to visualize the clusters\n",
    "def visualize_clusters(data, kmeans_model):\n",
    "n_clusters = len(np.unique(kmeans_model.labels_))\n",
    "title = 'Clusters of age against Charges'\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(n_clusters):\n",
    "cluster_data = data[data['Cluster'] == i]\n",
    "plt.scatter(cluster_data['charges'], cluster_data['age'], c=plt.cm.viridis(i / (n_clusters - 1)), label=f'Cluster {i+1}')\n",
    "plt.xlabel('Charges')\n",
    "plt.ylabel('age')\n",
    "plt.title(title, fontsize=16, fontweight='bold')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# Load the saved KMeans model\n",
    "model_file = 'kmeans_model.pkl'\n",
    "kmeans_model = joblib.load(model_file)\n",
    "\n",
    "# Create a new DataFrame with different data (replace this with your new data)\n",
    "# For demonstration, I'm creating a random DataFrame here\n",
    "new_data = pd.DataFrame({\n",
    "'age': np.random.randint(18, 70, size=100),\n",
    "'charges': np.random.uniform(1000, 50000, size=100),\n",
    "'smoker': np.random.choice(['yes', 'no'], size=100),\n",
    "'sex': np.random.choice(['male', 'female'], size=100)\n",
    "})\n",
    "\n",
    "# Preprocess the new data\n",
    "new_data_std = preprocess_data(new_data)\n",
    "\n",
    "# Predict clusters for the new data\n",
    "new_data['Cluster'] = kmeans_model.predict(new_data_std)\n",
    "\n",
    "# Visualize the clusters\n",
    "visualize_clusters(new_data, kmeans_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
